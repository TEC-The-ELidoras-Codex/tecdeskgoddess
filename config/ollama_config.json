{
  "local_ai": {
    "enabled": true,
    "provider": "ollama",
    "model_name": "qwen2:1.5b",
    "api_base": "http://localhost:11434",
    "settings": {
      "temperature": 0.7,
      "max_tokens": 512,
      "top_p": 0.9,
      "top_k": 40
    }
  }
}